{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"cs109b_hw3.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> Data Science 2: Advanced Topics in Data Science \n",
    "\n",
    "## Homework 3: Artificial Neural Networks, Model Interpretation, and Regularization\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2023**<br/>\n",
    "**Instructors**: Mark Glickman & Pavlos Protopapas\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 16:37:33.529847: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(109)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure notebook runtime\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Instructions\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Plots should be legible and interpretable without having to refer to the code that generated them, including labels for the $x$- and $y$-axes as well as a descriptive title and/or legend when appropriate.\n",
    "- When asked to interpret a visualization, do not simply describe it (e.g., \"the curve has a steep slope up\"), but instead explain what you think the plot *means*.\n",
    "- Autograding tests are mostly to help you debug. The tests are not exhaustive so passing a test is necessary but not sufficient for full credit. \n",
    "- The use of *extremely* inefficient or error-prone code (e.g., copy-pasting nearly identical commands rather than looping) may result in only partial credit.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. Please get course staff approval before importing any additional 3rd party libraries.\n",
    "- Enable scrolling output on cells with very long output.\n",
    "- Feel free to add additional code or markdown cells as needed.\n",
    "- Ensure your code runs top to bottom without error and passes all tests by restarting the kernel and running all cells (note that this can take a few minutes). \n",
    "- **You should do a \"Restart Kernel and Run All Cells\" before submitting to ensure (1) your notebook actually runs and (2) all output is visible**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "# Notebook Contents\n",
    "\n",
    "- [**PART 1 [65 pts]: Model interpretation and predictive intervals in ANNs**](#part1)\n",
    "  - [Overview and Data Description](#part1intro)\n",
    "  - [Questions](#part1questions)\n",
    "\n",
    "\n",
    "- [**PART 2 [35 pts]: Kannada MNIST Kaggle competition**](#part2)\n",
    "  - [Problem Statement](#part2intro)\n",
    "  - [The Kannada MNIST Dataset](#part2about)\n",
    "  - [Downloading the Data Files](#part2data)\n",
    "  - [CS109B Kaggle Competition](#part2kaggle)\n",
    "  - [Questions](#part2questions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "    \n",
    "<!-- <div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\"> -->\n",
    "\n",
    "# PART 1 [65 pts]: Model interpretation and predictive intervals in ANNs\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "<a id=\"part1intro\"></a>\n",
    "\n",
    "## Overview and Data Description\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "In this problem, you will be building and interpreting models to predict whether a flight was delayed for its arrival. The model will be based on features that can be measured as the flight takes off.\n",
    "\n",
    "We will also estimate the predictive intervals of the model using bootstrapping. We will utilize those predictive intervals to build a new kind of model: a model that refrains from making a prediction when it is not confident.\n",
    "\n",
    "The variable in the original csv are:\n",
    "\n",
    "    \n",
    "**ARRIVAL_DELAY**: the difference between scheduled arrival and actual arrival, in minutes (positive is late, negative is early).\n",
    "\n",
    "**DISTANCE**: the distance between arrival and departure airports, in miles.\n",
    "\n",
    "**SCHEDULED_TIME**: the flight's scheduled travel time in minutes.\n",
    "\n",
    "**MONTH**: the month the flight took off, 1 = January, 2 = February, etc.\n",
    "\n",
    "**SCHED_DEP_HOUR**: the scheduled departure time (the hour of the day).\n",
    "\n",
    "**SCHED_ARR_HOUR**: the scheduled arrival time (the hour of the day).\n",
    "\n",
    "**FLIGHT_COUNT**: the number of flights flying out of the origin airport before noon on a typical day.\n",
    "\n",
    "**DAY_OF_WEEK**: the day of the week, 1 = Monday, 2 = Tuesday, etc.\n",
    "\n",
    "**ORIGIN_AIRPORT**: the airport the flight took off from.\n",
    "\n",
    "**DESTINATION_AIRPORT**: the airport the flight was scheduled to land at.\n",
    "\n",
    "For the airport codes, see: https://www.bts.gov/topics/airlines-and-airports/world-airport-codes\n",
    "\n",
    "To sucessfully complete this part, you will proceed by fitting a NN model, evaluating its accuracy, interpreting the predictors' importance, and finally evaluating the predictive intervals.\n",
    "\n",
    "**NOTE:** the observations were sampled so that roughly half of the observations were delayed and half of the observations were not delayed.\n",
    "\n",
    "<!-- </div> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1solutions\"></a>\n",
    "\n",
    "## PART 1 Questions\n",
    "\n",
    "[Return to contents](#contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.1**  **Preprocess the data**\n",
    "\n",
    "Our first step will be to read in our dataset and preprocess our data.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.1.1**   Read in the dataset `data/flights.csv` into a DataFrame called `df_flights`. Create a new column in the DataFrame called `DELAY_OR_NOT`. This is a binary variable that denotes whether `ARRIVAL_DELAY` is greater-than-or-equal-to 15 minutes (the FAA and BTS define a flight as delayed by 15 minutes or more). This is going to be the response variable for the rest of part 1. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here \n",
    "\n",
    "df_flights = pd.read_csv(\"/Users/jamesliounis/Documents/Harvard SM DS/AC209b/Problem Sets/cs109b_hw3/data/flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "delay = lambda x: 1 if x >= 15 else 0\n",
    "\n",
    "df_flights['DELAY_OR_NOT'] = df_flights['ARRIVAL_DELAY'].map(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1.1.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1.1.1 results: All test cases passed!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1.1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.1.2 Preprocess the data**\n",
    "    \n",
    "- Deal with missing values if there are any\n",
    "- One-hot-encode the non-numeric categorical variables\n",
    "- Split the data using an 80/20 train-test split with `random_state=109` and stratifying on the response variable\n",
    "- Standardize train and test with the scaler fit on the train data\n",
    "\n",
    "Print the resulting shapes of your $X$ and $y$ dataframes for both your train and your test sets.\n",
    "    \n",
    "**NOTE:** While inspecting your data, you may notice that a large number of airport codes are recorded using 5-digit values instead of the expected 3-letter codes. That is perfectly fine. Those 5-digit values should be considered valid and just be treated the same as they would be if they were 3-letter codes.\n",
    "\n",
    "**TIPS:** \n",
    "- month and day-of-the-week should be treated as numerical in this context.\n",
    "- you should consider what predctors are acceptable to include given our goal is to predict if a flight is delayed.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARRIVAL_DELAY          0\n",
      "DISTANCE               5\n",
      "SCHEDULED_TIME         1\n",
      "MONTH                  0\n",
      "SCHED_DEP_HOUR         0\n",
      "SCHED_ARR_HOUR         0\n",
      "FLIGHT_COUNT           5\n",
      "DAY_OF_WEEK            0\n",
      "ORIGIN_AIRPORT         0\n",
      "DESTINATION_AIRPORT    0\n",
      "DELAY_OR_NOT           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "print(df_flights.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only a handful of missing values in the dataframe and its only in variables that we hypothesize do not matter that much. Hence, we can probably just drop them without loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "df_flights = df_flights.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARRIVAL_DELAY            int64\n",
       "DISTANCE               float64\n",
       "SCHEDULED_TIME         float64\n",
       "MONTH                    int64\n",
       "SCHED_DEP_HOUR           int64\n",
       "SCHED_ARR_HOUR           int64\n",
       "FLIGHT_COUNT           float64\n",
       "DAY_OF_WEEK              int64\n",
       "ORIGIN_AIRPORT          object\n",
       "DESTINATION_AIRPORT     object\n",
       "DELAY_OR_NOT             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check which types our columns have\n",
    "# Need to OHE 'ORIGIN_AIRPORT' and 'DESTINATION_AIRPORT'\n",
    "\n",
    "df_flights.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the categorical variable\n",
    "df_flights = pd.get_dummies(df_flights, columns=['ORIGIN_AIRPORT', 'DESTINATION_AIRPORT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'DELAY_OR_NOT'\n",
    "\n",
    "# split the data into training and testing sets\n",
    "df_train, df_test = train_test_split(df_flights, \n",
    "                                     test_size=0.2, \n",
    "                                     random_state=109, \n",
    "                                     stratify=df_flights[y])\n",
    "\n",
    "# Fit standard scaler on the training data\n",
    "scaler = StandardScaler().fit(df_train)\n",
    "\n",
    "df_train_scaled = pd.DataFrame(scaler.transform(df_train), columns=df_flights.columns)\n",
    "df_test_scaled = pd.DataFrame(scaler.transform(df_test), columns=df_flights.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.2**  **Fit an ANN**\n",
    "\n",
    "Fit an artificial neural network model using all predictors (name this model `NN_model`).  Use a dense feed-forward network with two hidden layers with 15 nodes in each hidden layer. For this network, use a reasonable activation function for the hidden layers, select an appropriate loss function and optimizer, specify a validation split of 0.2, train for a reasonable number of epochs. Feel free to use tensorflow's default batch size while training. Plot the training accuracy and validation accuracy as a function of epochs from your `NN_model`'s training history. Evaluate the `NN_model` model on both train and test, and print out the resulting train and test accuracies.\n",
    "\n",
    "**Hint:** You should base your choice of \"a reasonable number of epochs\" on the visualization of the model's training history.\n",
    "\n",
    "<a id=\"q13\"></a>\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build your NN \n",
    "# your code here\n",
    "\n",
    "# extract the predictor variables and response variable \n",
    "# from the training and testing sets\n",
    "X_train = df_train_scaled.drop(y, axis=1)\n",
    "y_train = df_train_scaled[y]\n",
    "X_test = df_test_scaled.drop(y, axis=1)\n",
    "y_test = df_test_scaled[y]\n",
    "\n",
    "# define the ANN model\n",
    "\n",
    "n_hidden = 2\n",
    "hidden_size = 15\n",
    "batch_size = 16\n",
    "\n",
    "NN_model = tf.keras.Sequential()\n",
    "NN_model.add(tf.keras.Input(shape=X_train.shape[1]))\n",
    "for i in range(n_hidden):\n",
    "    NN_model.add(tf.keras.layers.Dense(hidden_size, activation='relu'))\n",
    "NN_model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "#model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# convert y_train and y_test to one-hot encoded format\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile it and run it\n",
    "# your code here \n",
    "# compile the model\n",
    "\n",
    "NN_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.6491 - accuracy: 0.6496 - val_loss: 0.5544 - val_accuracy: 0.7412\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7971 - val_loss: 0.4299 - val_accuracy: 0.8100\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8735 - val_loss: 0.3521 - val_accuracy: 0.8550\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9167 - val_loss: 0.3178 - val_accuracy: 0.8856\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9465 - val_loss: 0.2945 - val_accuracy: 0.9019\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.9540 - val_loss: 0.2902 - val_accuracy: 0.9150\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.9647 - val_loss: 0.2962 - val_accuracy: 0.9244\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9709 - val_loss: 0.3009 - val_accuracy: 0.9281\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9772 - val_loss: 0.3096 - val_accuracy: 0.9219\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9822 - val_loss: 0.3103 - val_accuracy: 0.9319\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 0.3189 - val_accuracy: 0.9262\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9867 - val_loss: 0.3308 - val_accuracy: 0.9319\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.3383 - val_accuracy: 0.9294\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9895 - val_loss: 0.3392 - val_accuracy: 0.9344\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 0.3423 - val_accuracy: 0.9369\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9902 - val_loss: 0.3507 - val_accuracy: 0.9306\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.3532 - val_accuracy: 0.9300\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.3731 - val_accuracy: 0.9325\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9886 - val_loss: 0.3597 - val_accuracy: 0.9319\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9925 - val_loss: 0.3670 - val_accuracy: 0.9344\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9928 - val_loss: 0.3683 - val_accuracy: 0.9344\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.3977 - val_accuracy: 0.9350\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 0.3695 - val_accuracy: 0.9388\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.3970 - val_accuracy: 0.9394\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.3896 - val_accuracy: 0.9369\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9936 - val_loss: 0.3981 - val_accuracy: 0.9406\n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.4128 - val_accuracy: 0.9369\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.3946 - val_accuracy: 0.9419\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9944 - val_loss: 0.4143 - val_accuracy: 0.9388\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9948 - val_loss: 0.4064 - val_accuracy: 0.9400\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.4187 - val_accuracy: 0.9394\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.4196 - val_accuracy: 0.9394\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9953 - val_loss: 0.4341 - val_accuracy: 0.9394\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.4318 - val_accuracy: 0.9388\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 0.9953 - val_loss: 0.4509 - val_accuracy: 0.9356\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.4526 - val_accuracy: 0.9337\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.4397 - val_accuracy: 0.9394\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 0.4292 - val_accuracy: 0.9400\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.4206 - val_accuracy: 0.9419\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.4120 - val_accuracy: 0.9419\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.4336 - val_accuracy: 0.9388\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.4223 - val_accuracy: 0.9394\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.4599 - val_accuracy: 0.9381\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.4415 - val_accuracy: 0.9406\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 0.9967 - val_loss: 0.4686 - val_accuracy: 0.9381\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 0.4571 - val_accuracy: 0.9369\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.4536 - val_accuracy: 0.9388\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 0.9962 - val_loss: 0.4923 - val_accuracy: 0.9388\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4709 - val_accuracy: 0.9406\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.4766 - val_accuracy: 0.9438\n"
     ]
    }
   ],
   "source": [
    "# plot train and val acc as a function of epochs\n",
    "# your code here\n",
    "\n",
    "# fit the model to the training data\n",
    "history = NN_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate on train and test and print accuracy results\n",
    "# your code here \n",
    "\n",
    "# plot the training and validation accuracy as a function of epochs\n",
    "plt.plot(history.history['accuracy'], color='blue')\n",
    "plt.plot(history.history['val_accuracy'], color='red')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9871\n",
      "Train accuracy: 0.9871185421943665\n",
      "63/63 [==============================] - 0s 840us/step - loss: 0.3605 - accuracy: 0.9490\n",
      "Test accuracy: 0.9489744901657104\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the training data\n",
    "train_loss, train_acc = NN_model.evaluate(X_train, y_train)\n",
    "print('Train accuracy:', train_acc)\n",
    "\n",
    "# evaluate the model on the test data\n",
    "test_loss, test_acc = NN_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.3**  **Fit and examine a \"proxy\" model**\n",
    "\n",
    "Neural networks are often called 'black-box' models because it is difficult to interpret just what role each feature plays in the predictions they output. But suppose we choose a second type of model which is easier to interpret and train it to *predict the predictions* of the`NN_model`. That is, the response variable for the second, \"proxy\" model is the set of predictions generated by the `NN_model`, $\\hat{y}$, **not** the true values, $y$. Interpreting this second, \"proxy\" model can then give us some insight into how the `NN_model` is making its predictions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.3.1**  First, generate a set of `NN_model` class predictions for the training set. Call these `y_train_nn`. These $\\hat{y}$ training predictions will be used instead of the true $y$ training values when we fit our proxy model in 1.3.2. The $X$ values used in our 1.3.2 proxy model should be the same ones used for `NN_model`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.3.2**  Next, fit a logistic regression model using your $\\hat{y}$ values from 1.3.1 (name this model `logreg`). Use ridge-like regularization. Next, print the `logreg` test accuracy compared to the *true $y$ values* to confirm that it is similar to what we saw for our `NN_model` test accuracy in 1.2. You may need to adjust `C` in order to achieve a similar accuracy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.3.3**  Now use sklearn's `permutation_importance` function (already included in this notebook's imports) to compute the feature importance using the `logreg` model. Plot the **relative** feature importance (normalizing your importances so that your largest importance equals 1 for comparison purposes) for the top-10 most important predictors identified by the `permutation_importance` function.\n",
    "\n",
    "  - Please refer to sklearn's official documentation to learn how this function works.\n",
    "  \n",
    "  - When running `permutation_importance` for this problem, you can use the default number of `n_repeats` and your estimator's default `scorer`. To speed up the time it takes to run your permutations, you can try setting `n_jobs=-1` to take full advantage of all of your available processor cores.\n",
    "\n",
    "<a id=\"q14\"></a>\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.4**  **Visualize important features** \n",
    "\n",
    "Another way to interpret the  `NN_model` is by examining the response as a function of any of the predictors. Particularly, we will select from features often found most significant from the analysis above. Though the data has been scaled, **for all plots in 1.4, please visualize using the original scale for interpretability.**\n",
    "\n",
    "**NOTE:** The predictors you are required to use in 1.4 may differ from some of the top-10 predictors you identified in 1.3 as a result of random variability in our algorithms.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.4.1**\n",
    "    \n",
    "Set all predictors to their means/modes except for `SCHED_DEP_HOUR` (when deciding between mean and mode, consider whether a given predictor is continous or categorical.\n",
    "    \n",
    "Next, predict the `NN_model` probability of delay and plot the predicted probabilities of delay vs. `SCHED_DEP_HOUR` on the data from the **training set**. Interpret what you see in 2-4 sentences.\n",
    "\n",
    "**NOTE:** Again, the values of `SCHED_DEP_HOUR` used her for predictions and plotting should be those actually *observed* in the training data.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.4.2**  Set all predictors to their means/modes except for `SCHED_DEP_HOUR` and `FLIGHT_COUNT`. Predict the `NN_model` probability of delay and plot the predicted probabilities of delay vs. values `SCHED_DEP_HOUR` and `FLIGHT_COUNT` observed in the training set.  \n",
    "    \n",
    "**NOTE:** See hint in 1.4.5 about plotting in this section\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.4.3**  Set all predictors to their means/modes except for `SCHED_DEP_HOUR` and `SCHED_ARR_HOUR`. Predict the `NN_model` probability of delay and plot the predicted probabilities of delay vs. values of `SCHED_DEP_HOUR` and `SCHED_ARR_HOUR` observed in the training set.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.4.4**  Set all predictors to their means/modes except for `SCHED_DEP_HOUR` and `DISTANCE`. Predict the `NN_model` probability of delay and plot the predicted probabilities of delay vs. values of `SCHED_DEP_HOUR` and `DISTANCE` observed in the training set. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.4.5**  In 5-10 sentences, interpret what you have seen in 1.4.2, 1.4.3, and 1.4.4.\n",
    "\n",
    "**HINT:** For 1.4.2, 1.4.3, and 1.4.4, when you include `SCHED_DEP_HOUR` on one axis and your second predictor on the other axis, you can color your data points based on their corresponding predicted probabilities by using  the `c` and `cmap` arguments in `plt.scatter`. You can also add a labeled colorbar to your plot to make clear what those colors mean. You can refer to the [matplotlib documentation](https://matplotlib.org/stable/tutorials/index) for examples. This [stackoverflow post](https://stackoverflow.com/questions/17682216/scatter-plot-and-color-mapping-in-python) covering color mapping with scatter plots may also be useful. \n",
    "\n",
    "<a id=\"q15\"></a>\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.5**  **Bootstrap prediction intervals**\n",
    "\n",
    "In this part, we will attempt to do model inference. Neural Networks have too many parameters, and therefore inference on all the parameters is intractable and meaningless. \n",
    "\n",
    "Using the same network architecture as `NN_model` (layers, nodes, activations, etc.) and your scaled data from that model, create multiple training sets using bootstrapping and fit a separate neural network model to each bootstrapped set of data (the number of bootstraped *datasets*, $n$, should be at least 50). For each of the $n$ models, make predictions on the test data. Randomly select 8 test observations and on 8 subplots, plot the distribution of the $n$ predicted probabilities with the 95% prediction intervals clearly marked and reported in each subplot and the **actual** class of each observation included in each subplot's title for easy reference.\n",
    "    \n",
    "Interpret what you see in 3-5 sentences.\n",
    "\n",
    "**NOTE:** The code for this problem can take an extremely long time to execute. Please feel free to use the `progressbar` function provided below to visually track the progress of your bootstraps.\n",
    "\n",
    "<a id=\"q16\"></a>\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressbar(n_step, n_total):\n",
    "    \"\"\"Prints self-updating progress bar to stdout to track for-loop progress\n",
    "    \n",
    "    There are entire 3rd-party libraries dedicated to custom progress-bars.\n",
    "    A simple function like this is often more than enough to get the job done.\n",
    "    \n",
    "    :param n_total: total number of expected for-loop iterations\n",
    "    :type n_total: int\n",
    "    :param n_step: current iteration number, starting at 0\n",
    "    :type n_step: int\n",
    "\n",
    "    .. example::\n",
    "    \n",
    "        for i in range(n_iterations):\n",
    "            progressbar(i, n_iterations)\n",
    "            \n",
    "    .. source:\n",
    "    \n",
    "        This function is a simplified version of code found here:\n",
    "        https://stackoverflow.com/questions/3160699/python-progress-bar/15860757#15860757\n",
    "    \"\"\"\n",
    "    n_step = n_step + 1\n",
    "    barlen = 50\n",
    "    progress = n_step / n_total\n",
    "    block = int(round(barlen * progress))\n",
    "    status = \"\"\n",
    "    if n_step == n_total:\n",
    "        status = \"Done...\\r\\n\\n\"\n",
    "    text = \"\\r [{0}] {1}/{2} {3}\".format(\n",
    "        \"=\" * block + \"-\" * (barlen - block),\n",
    "        n_step,\n",
    "        n_total,\n",
    "        status,\n",
    "    )\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Bootstrap and train your networks and get predictions on X test\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate your plot\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**1.6**  **Build an \"abstain\" bagging model**\n",
    "\n",
    "Using the probability distribution of the predictions obtained from the bootstrapped samples above, we can evaluate how confident we should be in our bagged (i.e. bootstrap-aggregated) predictions for each test observation.\n",
    "\n",
    "To accomplish this, you will first calculate a metric we'll call the **Posterior Prediction Dissent (PPD)** related to the proportion of predictions a given test observation receives for the minority opinion. Some examples: if 10% of the bootstrapped models predict $\\hat{y} = 0$ with the remaining 90% predicting $\\hat{y}=1$, then the $PPD=0.1$. When a bagged prediction's $PPD=0$, all predictions are compatible (i.e. all bootstrapped probabilities for that test observation are on the same side of $\\hat{p}=0.5$). Likewise, when the $PPD=0.5$, half of the bootstrapped predictions for that test observation are $\\hat{y}=0$, and the other half are $\\hat{y}=1$. After calculating your $PPD$ values for all test observations, you should have $n=2000$ $PPD$ values (i.e. one for each test observation).\n",
    "\n",
    "Next, to get more accurate predictions, we can create an **abstain** model that will abstain from making a prediction for a particular observation if some defined threshold for lack-of-confidence (i.e. maximum permissible $PPD$ value) is crossed. (If you'd like to learn more about abstain models, you can read more [here](https://openreview.net/forum?id=rJxF73R9tX).)\n",
    "\n",
    "Let's explore how your resulting test accuracies might change by using your bootstrapped prediction results from question 1.5 for an **abstain bagging model** (i.e. a bootstrap aggregated model where some test observations are simply not predicted based on a given $PPD$ threshold). You can make your abstain model *stricter* by using smaller $PPD$ threshold values.\n",
    "\n",
    "- Print the test accuracy for your **bagging model** predictions from question 1.5 using predictions for all 2,000 of our test observations. \n",
    "\n",
    "- Plot the test accuracies for an **abstain bagging model** using your predictions from question 1.5 as a function of increasing $PPD$.\n",
    "\n",
    "- Also, plot the proportion of test observations not abstained (i.e. the proportion of those predicted) for your **abstain bagging model** as a function of increasing $PPD$.\n",
    "\n",
    "- Interpret what you see in 3-5 sentences.\n",
    "\n",
    "**NOTE**: You should observe that as $PPD$ decreases (more confident predictions), you must also compromise on the number of points that your abstain model is permitted to predict on. \n",
    "\n",
    "**HINT:** \n",
    "- What is the range of values PPD can take on? Is it the same as the range of our predictions themselves?\n",
    "- When calculating accuracies, you should only consider those observations that received predictions (i.e., not the abstained observations)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "\n",
    "<!-- <div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\"> -->\n",
    "\n",
    "# PART 2 [35 pts]: Kannada MNIST Kaggle competition\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "\n",
    "<a id=\"part2intro\"></a>\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "\n",
    "Artificial neural networks (ANNs) can be prone to overfitting, where they learn specific patterns present in the training data, but the patterns do not generalize to new data.\n",
    "\n",
    "There are several methods used to improve ANN generalization. \n",
    "\n",
    "One approach is to use an architecture just barely wide or deep enough to fit the data. The idea here is that smaller networks are less expressive and thus less able to overfit the data.\n",
    "\n",
    "However, it is difficult to know a priori the correct size of the ANN, and it is computationally costly to hunt for the correct size. Given this, other methodologies are used to prevent overfitting and improve ANNs' generalizability. These methodologies, like other techniques that combat overfitting, fall under the umbrella term of \"regularization\".\n",
    "\n",
    "In this problem, you are asked to regularize a network of a given architecture.\n",
    "\n",
    "<a id=\"part2about\"></a>\n",
    "\n",
    "## The Kannada MNIST Dataset\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "\n",
    "![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3630446%2F1e01bcc28b5ccb7ad38a4ffefb13cde0%2Fwondu.png?generation=1603204077179447&alt=media)\n",
    "\n",
    "\n",
    "For this problem, we will be working with a modified version of the [Kannada MNIST dataset](https://arxiv.org/pdf/1908.01242.pdf), which is a large database of handwritten digits in the indigenous language *Kannada*.\n",
    "\n",
    "This dataset consists of 60,000 28x28 grayscale images of the ten digits, along with a test set of 10,000 images. \n",
    "\n",
    "For this homework, we will simplify the problem by only using the digits labeled `0` and `1` owing to the similarity of the two symbols, and we will use a total of 1,200 samples for training (this includes the data you will use for validation).\n",
    "\n",
    "To understand the dataset better, we recommend this [article](https://towardsdatascience.com/a-new-handwritten-digits-dataset-in-ml-town-kannada-mnist-69df0f2d1456) by Vinay Prabhu, the curator of the dataset.\n",
    "\n",
    "<a id=\"part2data\"></a>\n",
    "\n",
    "## Downloading the Data Files\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "\n",
    "**Please download the specific `kmnist_train.csv` and `kmnist_test.csv` data files available on [the \"Data\" tab of the CS109B HW3 Kaggle Competition website](https://www.kaggle.com/t/91152696a0cf4872adedafbaff0f7f15). (DO NOT USE DATA FROM ANY OTHER SOURCE!)**\n",
    "\n",
    "Here's a brief description of the data files:\n",
    "\n",
    "- `kmnist_train.csv` is our training dataset and the last column contains our response class. The 784 other columns correspond to the pixel values of the 28x28 dimension image. Class 0 means a sample is the handwritten digit `0` and class 1 means a sample is the handwritten digit `1` in the Kannada written language. `kmnist_train.csv` has 1,200 samples.\n",
    "\n",
    "\n",
    "- `kmnist_test.csv` has a structure similar to `kmnist_train.csv`, however the class label column is NOT included in with the test set. `kmnist_test.csv` has 2,000 samples. \n",
    "\n",
    "\n",
    "Kaggle leaderboard scores are accuracy scores calculated by Kaggle when you upload your predictions on this test set.\n",
    "\n",
    "- `sample_submission.csv` is the format that kaggle will accept. The uploaded `.csv` must contain 2 columns. The first column must be named `id` and needs to contain the test observation index numbers for each prediction, the second must be named `category` and needs to contain your class predictions (i.e. `0` or `1`) for each corresponding test observation index location. \n",
    "\n",
    "<a id=\"part2kaggle\"></a>\n",
    "\n",
    "## CS109B Kaggle Competition\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**ACCESS AND JOIN THE COMPETITION**:\n",
    "\n",
    "**You need to create an account on Kaggle and [join the competition via this link](https://www.kaggle.com/t/91152696a0cf4872adedafbaff0f7f15). This is a limited participation competition. Please DO NOT share this link.**\n",
    "\n",
    "**For more information on the rules** governing this CS109B Kaggle competition, please see below and also review [the modelling restrictions DOS and DON'TS outlined in question 2.3.1](#q2.3.1).\n",
    "\n",
    "**IMPORTANT NOTES ABOUT SCORING**:\n",
    "\n",
    "- The **public leaderboard** on Kaggle displays your performance on only 30% of the test set.\n",
    "\n",
    "\n",
    "- After the competition is complete, the **private leaderboard** will show your performance on the remaining 70% of the test set.\n",
    "\n",
    "- Question 2.3.5 is worth 5 points (the entire notebook is scored out of 100). Points for this questions will be awarded based on the **private leaderboard** as follows.\n",
    "\n",
    "|Private Leaderboard Score   | Points|\n",
    "|----------------------------|-------|\n",
    "|$0.945 \\leq \\text{score}$ |5|\n",
    "|$0.944 \\leq \\text{score} \\lt 0.945$|4|\n",
    "|$0.93 \\leq \\text{score} \\lt 0.94$|3|\n",
    "|$0.92 \\leq \\text{score} \\lt 0.93$|2|\n",
    "|$0.889 \\leq \\text{score} \\lt 0.92$|1|\n",
    "\n",
    "** Grand Prize(s):** The **Top-4** students on the private leaderboard will win an invitation to dinner with Pavlos and some of the CS109B teaching staff. This refers to the top 4 individuals on the board. The invitation will be extended to 5 students if the restriction to 4 would otherwise divide a group (e.g., 3 single submissions at the top followed by a group of 2).\n",
    "\n",
    "**ADDITIONAL COMPETITION RULES:**\n",
    "\n",
    "- Multiple Kaggle submissions are permitted (with a maximum of 20 submissions per-participant per-day), **just note that you will need to choose, on Kaggle, the ONE single submission to use for final scoring prior to the final HW3 submission deadline**, and **your submitted notebook MUST contain the matching code and model that generated your ONE chosen submission.**\n",
    "\n",
    "\n",
    "- **To repeat this point, the version of your final HW3 notebook submitted on Canvas MUST contain the same code and exact same model used to generate your ONE chosen Kaggle submission.** (TFs may rerun your notebook code to ensure comparable final leaderboard results.)\n",
    "\n",
    "\n",
    "- **Please do not manually label your submissions.** In other words, the labels should only be the outcome of your model.\n",
    "\n",
    "\n",
    "- **No external data are allowed, you MUST USE ONLY the KMNIST training and test data downloaded via the \"Data\" tab of [the CS109B competition page linked above](#part2data).**\n",
    "\n",
    "\n",
    "- **Do not** create multiple accounts on Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.1**  **Get and visualize the data**\n",
    "\n",
    "- Download the train and test data from [the competition page](#part2data).\n",
    "- We will utilize `kmnist_test.csv` in question 2.3.4 only. \n",
    "- Load the data and use the matplotlib function `imshow` to display a handwritten 0 and a handwritten 1 from the training set.\n",
    "- You are responsible for any preprocessing you deem necessary to help in your prediction task.\n",
    "\n",
    "<a id=\"q22\"></a>\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.2**  **Overfit an ANN** \n",
    "\n",
    "Build and fit a fully-connected network (FCN) with the architecture given below using `tensorflow.keras` and assign it to a variable called `model_overfit`:\n",
    "\n",
    "- Number of hidden layers: 3\n",
    "- Nodes per hidden layer: 100, 100, 100\n",
    "- Activation function: ReLU \n",
    "- Loss function: binary_crossentropy\n",
    "- Output unit: Sigmoid \n",
    "- Optimizer: adam (use the defaults; no other tuning)\n",
    "- Epochs: 1,000\n",
    "- Batch size: 128\n",
    "- Validation size: 0.3\n",
    "\n",
    "![diagram](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3630446%2F6a491ff8d4ff590dc8ded9a25461cd4b%2FScreenshot%202020-10-20%20at%209.42.36%20PM.png?generation=1603210420701577&alt=media) \n",
    "    \n",
    "This ANN, when trained on the dataset, will overfit to the training set. Plot the training accuracy and validation accuracy (the x-axis should represent the number of epochs, and the y-axis should represent the accuracy). Explain how you can tell the model is overfitting. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.3.1**  **Regularize the overfit network**\n",
    "\n",
    "Create an ANN that doesn't overfit and use it to [compete on Kaggle](#part2kaggle).\n",
    "\n",
    "<a id=\"q2.3.1\"></a>\n",
    "    \n",
    "**DON'TS**\n",
    "\n",
    "- **DO NOT change the architecture**. In other words, keep the same number of layers, same number of nodes, same activation function, and same loss function and output unit as was used in your question 2.2 overfit model. **No CNNs, RNNs, ensembles, or fancy enhancements.**\n",
    "\n",
    "- **DO NOT manually label your submissions.** In other words, the labels should only be the outcome of your model.\n",
    "\n",
    "- **DO NOT use any external data.** Please use ONLY the specific KMNIST datasets provided to you (via the CS109B [data link above](#part2data)) for training your model and for generating your test predictions.\n",
    "\n",
    "**DOS**\n",
    "\n",
    " - **YOU CAN change the** number of epochs (max 2000), batch size, optimizer, and of course, add elements that can help to regularize your model (e.g., dropout, L2 norm, etc.).\n",
    " - **YOU CAN also** do data augmentation using the provided training data. \n",
    " - **YOU CAN** add flatten layers as you see fit.\n",
    "\n",
    "**IMPORTANT: YOU MUST** ensure that the version of the code and model in your final submitted notebook is the **EXACT SAME** code and model used to generate your Kaggle submission. TFs may run your submitted model to ensure comparable results. **Other Kaggle competition rules and scoring details [are listed here](#part2kaggle).**\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.3.2**  Plot your model's training accuracy and validation accuracy as a function of epochs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.3.3**  In a few sentences, describe the various approaches you have taken to improve the performance of your regularized model in 2.3.1 as well as any observations you might have regarding your training and Kaggle results.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.3.4**  Generate your test-set class predictions using your regularized model. Save those predictions to a `.csv` formatted file. Submit that `.csv` file [to the CS109B Kaggle Competition](#part2kaggle) for leaderboard scoring. **IMPORTANT:** For Kaggle to accept and score your submitted `.csv` file, it MUST contain 2 columns. The first column must be named `\"Id\"` and needs to contain the test observation index numbers corresponding to each of your 2,000 predictions (index starting at `0`), the second column must be named `\"Category\"` and needs to contain your class predictions (i.e. `0` or `1`) for each corresponding test observation index location. Both columns should contain integer data types.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise-r'>\n",
    "\n",
    "**2.3.5**  **Specify your Kaggle name that you have used on the leaderboard**. We CANNOT give you credit without this.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise-r'><b>2.4 Wrap-up</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In a few sentences, please describe the aspect(s) of the assignment you found most challenging. This could be conceptual and/or related to coding and implementation.\n",
    "\n",
    "* How many hours did you spend working on this assignment? Store this as an int or float in `hours_spent_on_hw`. If you worked on the project in a group, report the *average* time spent per person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hours_spent_on_hw = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_end = time.time()\n",
    "print(f\"It took {(time_end - time_start)/60:.2f} minutes for this notebook to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This concludes HW3. Thank you!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1.1": {
     "name": "q1.1.1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sorted(df_flights.DELAY_OR_NOT.unique()) == [0, 1], \"Your new 'DELAY_OR_NOT' column should be a binary response variable\"\n>>> assert df_flights[\"DELAY_OR_NOT\"].value_counts().sort_index()[0] == 5069, \"Check how you are creating your 'DELAYED_OR_NOT' variable\" \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3.1": {
     "name": "q1.3.1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(y_train_nn) == 8000, \"Your NN predictions should match the length of the training data\"\n>>> assert sorted(np.unique(y_train_nn)) == [0, 1], \"Your new `y_train_nn` should consist of binary predictions\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert float(hours_spent_on_hw),\\\n...     \"Please select a time in hours (int or float) to specify how long you spent on this assignment.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

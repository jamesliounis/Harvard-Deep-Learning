{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"cs109b_hw1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "## Homework 1 - Clustering\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2023**<br/>\n",
    "**Instructors**: Mark Glickman & Pavlos Protopapas \n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Instructions\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Plots should be legible and interpretable without having to refer to the code that generated them, including labels for the $x$- and $y$-axes as well as a descriptive title and/or legend when appropriate.\n",
    "- When asked to interpret a visualization, do not simply describe it (e.g., \"the curve has a steep slope up\"), but instead explain what you think the plot *means*.\n",
    "- Autograding tests are mostly to help you debug. The tests are not exhaustive so passing a test is necessary but not sufficient for full credit. \n",
    "- The use of *extremely* inefficient or error-prone code (e.g., copy-pasting nearly identical commands rather than looping) may result in only partial credit.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. Please get course staff approval before importing any additional 3rd party libraries.\n",
    "- Enable scrolling output on cells with very long output.\n",
    "- Feel free to add additional code or markdown cells as needed.\n",
    "- Ensure your code runs top to bottom without error and passes all tests by restarting the kernel and running all cells (note that this can take a few minutes). \n",
    "- **You should do a \"Restart Kernel and Run All Cells\" before submitting to ensure (1) your notebook actually runs and (2) all output is visible**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from gap_statistic import OptimalK\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, ward\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure notebook runtime\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "# Notebook Contents\n",
    "\n",
    "- [**Problem 1 [37.5 pts]: Clustering with k-means**](#part1)\n",
    "\n",
    "- [**Problem 2 [37.5 pts]: Other Ks**](#part2)\n",
    "  \n",
    "- [**Problem 3 [25 pts]: Alternative Algorithms**](#part3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"theme\">FMA: A Dataset For Music Analysis </div>\n",
    "\n",
    "In this assignment, you will be working with data collected from The Free Music Archive (https://freemusicarchive.org/). The Free Music Archive is an online repository of original music from independent artists that can be freely downloaded as an mp3. \n",
    "\n",
    "The provided `fma_new.csv` contains 9,354 rows.\n",
    "\n",
    "In this subset of the FMA data, each music track is represented by a total of 82 summary audio features:\n",
    "\n",
    "8 interpretable features extracted by Echonest (now Spotify):\\\n",
    "`acousticness`, `danceability`, `energy`, `instrumentalness`, `liveness`, `speechiness`, `tempo`, `valence`\n",
    "\n",
    "\n",
    "74 abstract audio features computated across the run time of the track using the [librosa](https://librosa.org/doc/latest/index.html) python package and then averaged. \n",
    "\n",
    "For those interestend in more information about the FMA dataset please see the paper and GitHub repository (https://github.com/mdeff/fma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"part1\"></a>\n",
    "\n",
    "## <div class='exercise'>Part 1: Clustering with k-means </div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q1.1 Loading Data, Scaling, and KMeans Clustering</b></div>\n",
    "    \n",
    "Begin by reading `data/fma_new.csv` into a Pandas DataFrame called `fma`.  \n",
    "\n",
    "You can assume that this particular subset of the FMA data includes 12 different music genres. So we'll begin by assuming there are 12 clusters. \n",
    "\n",
    "But before we begin clustering we should standardize the dataset so that all features have mean of 0 and standard deviation of 1. In this way the distance metric used by out clustering algorithms will not be affect by the arbitrary scale of the features. Save the standardized data in DataFrame called `fma_scaled` which has the same column names as `fma`.\n",
    "\n",
    "Next, run the k-means clustering algorithm on the scaled data using the `KMeans` class from `sklearn.cluster`, setting the number of clusters to 12, `n_init` to 25, and the `random_state` to 109.  Save the fitted KMeans object as `km12`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "fma = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q1.2 Evaluating $k=12$</b></div>\n",
    "\n",
    "The provided `silplot` function creates two subplots: one displays the silhouette scores for each datapoint across all clusters and the other shows a projection of the data onto its first 2 principal components. In both subplots the assigned cluster labels are encoded by color.\n",
    "\n",
    "How reasonable does the clustering with $k=12$ appear? Use your understanding of the silhouette scores and PCA projection to support your position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified code from http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "def silplot(X, cluster_labels, clusterer, pointlabels=None):\n",
    "    n_clusters = clusterer.n_clusters\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12,7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example we \n",
    "    # will set a lower limit on the x-axis to keep the plot small\n",
    "    ax1.set_xlim([-0.2, 1])\n",
    "    \n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette_score is {silhouette_avg}.\")\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(0,n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = plt.cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = plt.cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    \n",
    "    # axes will be first 2 PCA components\n",
    "    \n",
    "    pca = PCA(n_components=2).fit(X.values)\n",
    "    X_pca = pca.transform(X.values) \n",
    "    ax2.scatter(X_pca[:, 0], X_pca[:, 1], marker='.', s=200, lw=0, alpha=0.35,\n",
    "                c=colors, edgecolor='k')\n",
    "    xs = X_pca[:, 0]\n",
    "    ys = X_pca[:, 1]    \n",
    "\n",
    "    \n",
    "    if pointlabels is not None:\n",
    "        for i in range(len(xs)):\n",
    "            plt.text(xs[i],ys[i],pointlabels[i])\n",
    "\n",
    "    # Labeling the clusters (transform to PCA space for plotting)\n",
    "    centers = pca.transform(clusterer.cluster_centers_)\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % int(i), alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC1 ({}%)\".format(np.round(100*pca.explained_variance_ratio_[0],1)))\n",
    "    ax2.set_ylabel(\"PC2 ({}%)\".format(np.round(100*pca.explained_variance_ratio_[1],1)))\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<a id=\"part2\"></a>\n",
    "\n",
    "## <div class='exercise'>Part 2: Other Ks </div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "Our choice of $k=12$ was just a guess based on the fact that we've been told there are 12 genres represented in this data.\\\n",
    "We'll now look at some metrics we can use to evaluate a set of clusters.\n",
    "\n",
    "**For questions in this section (Part 2) you should work with a sample of 2,000 data points drawn with the DataFrame `sample`method and a random seed of 109.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.1 Inertia</b></div>\n",
    "\n",
    "Here you'll use the elbow method to evaluate the best choice of $k$, plotting the total inertia of each k-means clustering for $k \\in \\{1,2,...,15\\}.$\n",
    "\n",
    "Running kmeans across many values of $k$ can take a long time so we'll take a few steps to speed things up.\n",
    "\n",
    "First, you should only be clustering a subset of the scaled data in this section (part 2). Using the DataFrame's `sample` method with a `random_state` of 109, sample 2,000 data points and store them in `processed_sample`.\n",
    "\n",
    "Next, when fiting each KMeans object, use only 10 initializations and a random state of 109 as before.\n",
    "\n",
    "Finally, create a well labeled plot of inertia as a function of $k$ and describe what value(s) of $k$ might be considered optimal with respect to this plot and why.\n",
    "\n",
    "**Note:** recall that inertia is twice the total within-cluster variation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.2 Silhouette Score</b></div>\n",
    "\n",
    "Using the labels from each of the 15 fitted KMeans objects in the previous question, calculate the average silhouette scores and store them in `sil_scores`. \n",
    "\n",
    "Plot the average silhouette scores in `sil_scores` as a function of $k$. Describe what value(s) of $k$ might be considered optimal with respect to this plot and why.\n",
    "\n",
    "**Hints:**\n",
    "* If you stored your results from Q2.1 you shouldn't have to refit any KMeans objects here\n",
    "* `silhouette_score` will throw an error if you try and score labels containing only a single cluster. Note that the silhouette score when $k=1$ is definte to be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.3 Gap Statistic</b></div>\n",
    "\n",
    "Use the gap statistic to evaluate the choice of the number of clusters for k-means clustering with $k \\in \\{1,2,..,15\\}$. Again, use `processed_sample` rather than the entire dataset to save time. \n",
    "\n",
    "Create a well-labeled plot showing the gap statistic as a function of the number of clusters.\n",
    "\n",
    "Describe the rule for picking the optimum number of clusters described in [the original gap statistic paper](https://hastie.su.domains/Papers/gap.pdf) (this is the method referred to in lecture as allowing for some \"slack\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This implementation of gap statistic has a [difficulties with reproducibility](https://github.com/milesgranger/gap_statistic/issues/59) so don't worry if your results change across runs. Setting a random seed with numpy and setting OptimalK's `n_jobs=1` helps, but it makes everything run unbearably slow. \n",
    "\n",
    "**Hint:** The [gap_statistic GitHub repo](https://github.com/milesgranger/gap_statistic) is a good place to find information about the `OptimalK` object and its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore the frame.append warning described here:\n",
    "# https://github.com/milesgranger/gap_statistic/issues/57\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Use the stopping condition described in the original paper\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.4 Choose a Best $k$</b></div>\n",
    "\n",
    "After analyzing the plots produced by all three of these metrics, discuss the number of k-means clusters that you think is the best fit for this dataset. Defend your answer with evidence from the three graphs produced here and what you surmise about this dataset. Store your choice in `best_k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.5 Visualize & Interpret Best $k$ Results</b></div>\n",
    "\n",
    "Fit KMeans on the *entire scaled dataset* using your choice of `best_k`, 25 initializations, and a random state of 109. Store the KMeans object in `km_best` and the resulting labels in `km_labels`. \n",
    "\n",
    "Next, use `silplot` to visualize these clusters and their silhouette scores. \n",
    "\n",
    "How do these plots differ from the previous pair, and what might that mean about the clusterings? Would you consider your kmeans clustering with `best_k` successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part3\"></a>\n",
    "\n",
    "## <div class='exercise'>Part 3: Alternative Algorithms </div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q3.1: Hierarchical Clustering</b></div>\n",
    "\n",
    "Run agglomerative clustering using Ward's method and plot the result using a dendrogram.\n",
    "\n",
    "Next, create a well-labeled plot of average silhoutte score as a function of the number of clusters, again with $k \\in \\{1,2,..,15\\}$. To do this you'll need to produce a series of 'flat' cluster labels using `fcluster` for each value of $k$ and then use those labels to calculate the averate silhouette scores.\n",
    "\n",
    "Use information from the dedrogram and silhouette scores plot to justify a choice for the optimal number of clusters. Store this interger in `maxclust`. Then use  to find the 'flat' cluster labels produced when `maxclust` is used as the maximum number of clusters. Store these labels in `hac_labels`.\n",
    "\n",
    "**Hint:**\n",
    "- When using a lot of data, rendering an x-axis label for each observation can make the dendrogram plotting very slow. Try setting `no_labels=True`.\n",
    "- Inspect the unique cluster labels produced by `fcluster`. Notice how they are numbered. Keep this in mind as you may need to alter the labels if you plan to use them with functions that expect labels to be encoded like those from KMeans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q3.2: DBSCAN</b></div>\n",
    "\n",
    "Create a well-labeled knee plot to determine an optimal epsilon for when the min point parameter is 5. Then run DBSCAN on the data using your choice of `episilon` and the speficied `min_samples=5`.\n",
    "\n",
    "Store all labels produced in `dbscan_labels`.\\\n",
    "Store the number of *clusters* found by the algorithm in `dbscan_n_clusters`.\n",
    "\n",
    "Inspect the number of points that were assigned to each *label*. What does this tell you about the clusters and give a geometric interpretation of what kind of data might lead to this result of DBSCAN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q3.3</b></div>\n",
    "\n",
    "Load `data/track_info.csv` into the Dataframe `track_info` and inspect it. This track info corresponds to the data in `fma` row-for-row.\n",
    "\n",
    "Create a well-labeled plot or set of subplots that visualize the 'top genre' make-up of each cluster designated by the three sets of labels: `km_labels`, `hac_labels`, and `dbscan_labels`.\n",
    "\n",
    "What does your visualization demonstrate about how each clustering compares to the genre labels? Does any one clustering seem more successful at capturing genre distinctions?\n",
    "\n",
    "**Hint:** There are many ways you could approach this visuallization task. Experiment! You may also find it helpful to create plotting functions to handle some parts of the visualization if they are being repeated with slightly different parameters (e.g., cluster labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<a id=\"bonus\"></a>\n",
    "\n",
    "## <div class='exercise'>Wrap-up</div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only required section here is to report the amount of time you spent on this assignment.\n",
    "\n",
    "You are encouraged to use this space to continue to explore the fma dataset. You could:\n",
    "- Try different clustering methods (e.g., total linkage)\n",
    "- Attempt feature selection, engineering, or dimentionality reduction before clustering\n",
    "- Sample points from clusters and inspect their track information to get an idea what a cluster might represent\n",
    "- Find the nearest neighbors in the feature space to a track of interest\n",
    "- Pull in new data from the [FMA project](https://github.com/mdeff/fma). There are thousands of additional tracks to use (these were just the only ones that also had the Spotify features and track info available). And there are also hundreds of additional (abstract) audio feature columns that can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many hours did you spend working on this assignment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_spent_on_hw = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"bonus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_end = time.time()\n",
    "print(f\"It took {(time_end - time_start)/60:.2f} minutes for this notebook to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This concludes HW1. Thank you!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "bonus": {
     "name": "bonus",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert float(time_spent_on_hw),\\\n...     \"Please select a time in hours (int or float) to specify how long you spent on this assignment.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.1": {
     "name": "q1.1",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(fma) == pd.DataFrame,\\\n...     f\"fma should be a DataFrame\"\n>>> assert fma.shape == (9354, 82),\\\n...     f\"fma should have shape (9354, 82), but you have {fma_scaled.shape}\"\n>>> assert fma_scaled.shape == (9354, 82),\\\n...     f\"fma_scaled should have shape (9354, 82), but you have {fma_scaled.shape}\"\n>>> assert np.allclose(fma_scaled.mean(), 0),\\\n...     f\"features in fma_scaled should all have mean zero (or very close to zero),  but you have {fma_scaled.mean()}\"\n>>> assert np.allclose(fma_scaled.std(), 1, atol=1e-4),\\\n...     f\"features in fma_scaled should all have standard deviation 1 (or very close to 1),  but you have {fma_scaled.std()}\"\n>>> assert type(fma_scaled) == pd.DataFrame,\\\n...     f\"fma_scaled should be a DataFrame\"\n>>> assert all(fma.columns == fma_scaled.columns),\\\n...     \"fma and fma_scaled should have the same column names\"\n>>> assert type(km12) == KMeans,\\\n...     \"km12 should be an sklearn KMeans object\"\n>>> assert km12.n_clusters == 12,\\\n...     \"km12 should have been fit with 12 clusters\"\n>>> assert km12.random_state == 109,\\\n...     \"km12 should have been fit with a random_state of 109\"\n>>> assert km12.n_init == 25,\\\n...     \"km12 should have been fit with 25 initializations\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert processed_sample.shape == (2000, 82),\\\n...     f\"processed_sample should have shape (2000, 82) but you have {processed_sample.shape}\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(sil_scores) == 15,\\\n...     f\"You should have 15 elements in sil_scores but you have {len(sil_scores)}\"\n>>> assert sil_scores[0] == 0,\\\n...     f\"Remember that the silhouette score when there is a single cluster is defined to be 0.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (best_k > 1) and (best_k <= 15),\\\n...     \"Your choice of best k should really be an integer in [2, 15]\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.5": {
     "name": "q2.5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(km_best) == KMeans,\\\n...     \"km_best should be an sklearn KMeans object\"\n>>> assert km_best.n_clusters == best_k,\\\n...     f\"km_best should have been fit with {best_k} clusters\"\n>>> assert km_best.random_state == 109,\\\n...     \"km_best should have been fit with a random_state of 109\"\n>>> assert km_best.n_init == 25,\\\n...     \"km_best should have been fit with 25 initializations\"\n>>> assert km_labels.shape[0] == fma_scaled.shape[0],\\\n...     f\"km_labels should have {fma_scaled.shape[0]} elements, but it has {km_labels.shape[0]}\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (maxclust > 1) and (maxclust <= 50),\\\n...     \"Your choice of best maxclust should really be an integer in [2, 50]\"\n>>> assert hac_labels.shape[0] == fma_scaled.shape[0],\\\n...     f\"hac_labels should have {fma_scaled.shape[0]} elements, but it has {hac_labels.shape[0]}\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.2": {
     "name": "q3.2",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (np.unique(dbscan_labels) >= 0).sum() == dbscan_n_clusters,\\\n...     \"Your dbscan_n_clusters is incorrect. Think about what the label values mean.\"\n>>> assert dbscan_labels.shape[0] == fma_scaled.shape[0],\\\n...     f\"dbscan_labels should have {fma_scaled.shape[0]} elements, but it has {dbsca_labels.shape[0]}\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
